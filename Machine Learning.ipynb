{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('Healthcare_Providers_cleaned.csv')\n",
    "# Drop Unnecessary Columns\n",
    "df = df.drop(['City of the Provider','State Code of the Provider','Provider Type','HCPCS Code'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_columns = ['Entity Type of the Provider','Place of Service','HCPCS Drug Indicator']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# Create the OneHotEncoder object\n",
    "encoder = OneHotEncoder(sparse=False,drop='first')\n",
    "\n",
    "# Fit and transform the data\n",
    "encoded_columns = encoder.fit_transform(df[binary_columns])\n",
    "\n",
    "# Create DataFrame with encoded features\n",
    "encoded_df = pd.DataFrame(encoded_columns, columns=encoder.get_feature_names_out(binary_columns))\n",
    "\n",
    "# Combine the original DataFrame with the encoded DataFrame\n",
    "# Drop the original categorical columns from df and concatenate with encoded_df\n",
    "df_encoded = pd.concat([df.drop(columns=binary_columns), encoded_df], axis=1)\n",
    "\n",
    "df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "# Initialize RobustScaler\n",
    "robust_scaler = RobustScaler()\n",
    "\n",
    "# Apply RobustScaler to the df_encoded DataFrame\n",
    "df_encoded_scaled = pd.DataFrame(robust_scaler.fit_transform(df_encoded), columns=df_encoded.columns)\n",
    "\n",
    "# Display the scaled DataFrame\n",
    "df_encoded_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# Dimensionality Reduction with PCA to 2D and 3D\n",
    "pca_pipeline_2d = Pipeline([\n",
    "    ('pca', PCA(n_components=2))  # Reduce to 2 dimensions\n",
    "])\n",
    "\n",
    "pca_pipeline_3d = Pipeline([\n",
    "    ('pca', PCA(n_components=3))  # Reduce to 3 dimensions\n",
    "])\n",
    "\n",
    "X_pca_2d = pca_pipeline_2d.fit_transform(df_encoded_scaled)\n",
    "X_pca_3d = pca_pipeline_3d.fit_transform(df_encoded_scaled)\n",
    "\n",
    "# Elbow Method for K-Means\n",
    "inertia = []\n",
    "k_range = range(1, 11)\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(X_pca_2d)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "# Plot Elbow Method\n",
    "plt.figure(figsize=(12, 9))\n",
    "plt.plot(k_range, inertia, marker='o')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow Method for Optimal K')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# K-Means Clustering\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "labels_kmeans_2d = kmeans.fit_predict(X_pca_2d)\n",
    "labels_kmeans_3d = kmeans.fit_predict(X_pca_3d)\n",
    "\n",
    "# Compute distances to nearest cluster centers for anomaly detection\n",
    "distances_to_centers = pairwise_distances_argmin_min(X_pca_3d, kmeans.cluster_centers_)[1]\n",
    "distance_threshold = np.percentile(distances_to_centers, 90)  # Define a threshold\n",
    "is_anomaly_kmeans = distances_to_centers > distance_threshold\n",
    "\n",
    "# k-Distance Graph for DBSCAN\n",
    "def plot_k_distance_graph(X, k=5):\n",
    "    neigh = NearestNeighbors(n_neighbors=k)\n",
    "    neighbors = neigh.fit(X)\n",
    "    distances, indices = neighbors.kneighbors(X)\n",
    "    k_distances = distances[:, -1]  # Distance to k-th nearest neighbor\n",
    "    k_distances = np.sort(k_distances)\n",
    "    \n",
    "    plt.figure(figsize=(12, 9))\n",
    "    plt.plot(k_distances)\n",
    "    plt.xlabel('Points sorted by distance to {}-th nearest neighbor'.format(k))\n",
    "    plt.ylabel('Distance')\n",
    "    plt.title('k-Distance Graph')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Plot k-distance graph for 2D data\n",
    "plot_k_distance_graph(X_pca_2d, k=5)\n",
    "# DBSCAN Clustering\n",
    "dbscan = DBSCAN(eps=0.05, min_samples=5)\n",
    "labels_dbscan = dbscan.fit_predict(X_pca_2d)\n",
    "\n",
    "# Isolation Forest\n",
    "iso_forest = IsolationForest(contamination=0.1, random_state=42)\n",
    "outliers = iso_forest.fit_predict(X_pca_2d)\n",
    "is_anomaly_iso = outliers == -1\n",
    "\n",
    "# DataFrames for visualization\n",
    "df_kmeans_2d = pd.DataFrame(X_pca_2d, columns=['PC 1', 'PC 2'])\n",
    "df_kmeans_2d['Cluster'] = labels_kmeans_2d\n",
    "df_kmeans_2d['Anomaly'] = is_anomaly_kmeans\n",
    "\n",
    "df_kmeans_3d = pd.DataFrame(X_pca_3d, columns=['PC 1', 'PC 2', 'PC 3'])\n",
    "df_kmeans_3d['Cluster'] = labels_kmeans_3d\n",
    "df_kmeans_3d['Anomaly'] = is_anomaly_kmeans\n",
    "\n",
    "df_dbscan = pd.DataFrame(X_pca_2d, columns=['PC 1', 'PC 2'])\n",
    "df_dbscan['Cluster'] = labels_dbscan\n",
    "df_dbscan['Anomaly'] = df_dbscan['Cluster'] == -1\n",
    "\n",
    "df_iso = pd.DataFrame(X_pca_2d, columns=['PC 1', 'PC 2'])\n",
    "df_iso['Anomaly'] = is_anomaly_iso\n",
    "\n",
    "# Visualization Functions\n",
    "\n",
    "def plot_pie_chart(df, title):\n",
    "    anomaly_count = df['Anomaly'].sum()\n",
    "    normal_count = len(df) - anomaly_count\n",
    "    labels = ['Anomaly', 'Normal']\n",
    "    sizes = [anomaly_count, normal_count]\n",
    "    colors = ['red', 'blue']\n",
    "    \n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=140)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# K-Means Visualizations\n",
    "\n",
    "# Plot K-Means 2D Results\n",
    "fig_kmeans_2d = px.scatter(df_kmeans_2d, x='PC 1', y='PC 2', color='Anomaly',\n",
    "                          color_continuous_scale=['blue', 'red'],\n",
    "                          title='K-Means 2D Anomalies (PCA Reduced)',\n",
    "                          labels={'Anomaly': 'Anomaly (0 = Normal, 1 = Anomaly)'})\n",
    "fig_kmeans_2d.show()\n",
    "\n",
    "# Plot K-Means 3D Results\n",
    "fig_kmeans_3d = px.scatter_3d(df_kmeans_3d, x='PC 1', y='PC 2', z='PC 3', color='Anomaly',\n",
    "                          color_continuous_scale=['blue', 'red'],\n",
    "                          title='K-Means 3D Anomalies (PCA Reduced)',\n",
    "                          labels={'Anomaly': 'Anomaly (0 = Normal, 1 = Anomaly)'})\n",
    "# Add K-Means cluster centroids\n",
    "centroids = pd.DataFrame(kmeans.cluster_centers_, columns=['PC 1', 'PC 2', 'PC 3'])\n",
    "fig_kmeans_3d.add_scatter3d(x=centroids['PC 1'], y=centroids['PC 2'], z=centroids['PC 3'],\n",
    "                         mode='markers', marker=dict(size=12, color='red', symbol='cross'),\n",
    "                         name='Centroids')\n",
    "fig_kmeans_3d.show()\n",
    "\n",
    "# DBSCAN Visualizations\n",
    "\n",
    "# Plot DBSCAN 2D Results\n",
    "fig_dbscan_2d = px.scatter(df_dbscan, x='PC 1', y='PC 2', color='Anomaly',\n",
    "                          color_continuous_scale=['blue', 'red'],\n",
    "                          title='DBSCAN 2D Anomalies (PCA Reduced)',\n",
    "                          labels={'Anomaly': 'Anomaly (0 = Normal, 1 = Anomaly)'})\n",
    "fig_dbscan_2d.show()\n",
    "\n",
    "# Plot DBSCAN 3D Results (using the same PCA reduced data if available)\n",
    "fig_dbscan_3d = px.scatter_3d(pd.DataFrame(X_pca_3d, columns=['PC 1', 'PC 2', 'PC 3']).assign(Cluster=labels_dbscan),\n",
    "                          x='PC 1', y='PC 2', z='PC 3', color='Cluster',\n",
    "                          color_continuous_scale=['blue', 'red'],\n",
    "                          title='DBSCAN 3D Anomalies (PCA Reduced)',\n",
    "                          labels={'Cluster': 'Cluster ID'})\n",
    "fig_dbscan_3d.show()\n",
    "\n",
    "# Isolation Forest Visualizations\n",
    "\n",
    "# Plot Isolation Forest 2D Results\n",
    "fig_iso_2d = px.scatter(df_iso, x='PC 1', y='PC 2', color='Anomaly',\n",
    "                     color_continuous_scale=['blue', 'red'],\n",
    "                     title='Isolation Forest 2D Anomalies (PCA Reduced)',\n",
    "                     labels={'Anomaly': 'Anomaly (0 = Normal, 1 = Anomaly)'})\n",
    "fig_iso_2d.show()\n",
    "\n",
    "# Plot Isolation Forest 3D Results (using the same PCA reduced data if available)\n",
    "fig_iso_3d = px.scatter_3d(pd.DataFrame(X_pca_3d, columns=['PC 1', 'PC 2', 'PC 3']).assign(Anomaly=is_anomaly_iso),\n",
    "                          x='PC 1', y='PC 2', z='PC 3', color='Anomaly',\n",
    "                          color_continuous_scale=['blue', 'red'],\n",
    "                          title='Isolation Forest 3D Anomalies (PCA Reduced)',\n",
    "                          labels={'Anomaly': 'Anomaly (0 = Normal, 1 = Anomaly)'})\n",
    "fig_iso_3d.show()\n",
    "\n",
    "# Plot pie charts for each model\n",
    "plot_pie_chart(df_kmeans_2d, 'K-Means Anomaly vs Normal Distribution (2D)')\n",
    "plot_pie_chart(df_dbscan, 'DBSCAN Anomaly vs Normal Distribution (2D)')\n",
    "plot_pie_chart(df_iso, 'Isolation Forest Anomaly vs Normal Distribution (2D)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
