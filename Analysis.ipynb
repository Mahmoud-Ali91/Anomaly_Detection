{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medical Insurance (Medicare) Anomaly Detection Project As for Epsilon Graduation Project "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA Stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- Data Reading & Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Healthcare Providers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns' ,None) #to see all columns to understand them better\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2- Report Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' '*10,'Data Info:') # to Know general information about the dataset\n",
    "df.info()\n",
    "print('-'*100)\n",
    "print(' '*10,'Columns and Rows count:') #to get summary of the dataset\n",
    "print(df.shape)\n",
    "print('-'*100)\n",
    "print(' '*10,'Unique values of data in each column:')\n",
    "print(df.nunique()) #to see unique values in each column to understand them better\n",
    "print('-'*100)\n",
    "print(' '*10,'Missing values in each column:')\n",
    "print(df.isnull().sum()) #to see missing values in each column to understand them better \n",
    "print('-'*100)\n",
    "print(' '*10,'Check for duplicates:')\n",
    "print(df.duplicated().sum()) #to check for duplicates\n",
    "print('-'*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3- Data Transformation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Droping Unnecessary Columns for Analysis Process\n",
    "df = df.drop(['Gender of the Provider','index','National Provider Identifier','Last Name/Organization Name of the Provider','First Name of the Provider','Middle Initial of the Provider','Credentials of the Provider','Street Address 2 of the Provider','Street Address 1 of the Provider','Zip Code of the Provider','Country Code of the Provider','Medicare Participation Indicator','HCPCS Description'\n",
    "],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_convert = [\n",
    "    'Number of Services',\n",
    "    'Number of Medicare Beneficiaries',\n",
    "    'Number of Distinct Medicare Beneficiary/Per Day Services',\n",
    "    'Average Medicare Allowed Amount',\n",
    "    'Average Submitted Charge Amount',\n",
    "    'Average Medicare Standardized Amount',\n",
    "    'Average Medicare Payment Amount'\n",
    "]\n",
    "\n",
    "# Convert columns to numeric, coercing errors (non-numeric values become NaN)\n",
    "df[columns_to_convert] = df[columns_to_convert].apply(pd.to_numeric, errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "for column in columns_to_convert:\n",
    "    fig = px.histogram(df, x=column)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_convert = [\n",
    "    'Number of Services',\n",
    "    'Number of Medicare Beneficiaries',\n",
    "    'Number of Distinct Medicare Beneficiary/Per Day Services',\n",
    "    'Average Medicare Allowed Amount',\n",
    "    'Average Submitted Charge Amount',\n",
    "    'Average Medicare Standardized Amount',\n",
    "    'Average Medicare Payment Amount'\n",
    "]\n",
    "\n",
    "# Find and replace with NaN \n",
    "df[columns_to_convert] = df[columns_to_convert].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Convert the columns to float\n",
    "df[columns_to_convert] = df[columns_to_convert].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Original shape: {df.shape}\")\n",
    "\n",
    "# Remove rows with any NaN values in the specified columns\n",
    "df = df.dropna(subset=columns_to_convert)\n",
    "\n",
    "# Print the shape before and after to see how many rows were removed\n",
    "print(f\"Shape after removing rows with NaNs: {df.shape}\")\n",
    "\n",
    "# Check if there are any NaNs left in these columns\n",
    "print(\"\\nNaN counts after removal:\")\n",
    "print(df[columns_to_convert].isna().sum())\n",
    "\n",
    "# Optionally, reset the index if needed\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "for column in columns_to_convert:\n",
    "    fig = px.histogram(df, x=column)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the cleaned dataset to a new CSV file\n",
    "df.to_csv('Healthcare_Providers_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4- Analysis & Pattern Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1- Categorical Features Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping columns of binary features\n",
    "label_mapping = {'I': 'Individual','O': 'Organization'}\n",
    "df['Entity Type of the Provider'] = df['Entity Type of the Provider'].map(label_mapping)\n",
    "place_of_service_mapping = {'F': 'Facility','O': 'Non-Facility'}\n",
    "df['Place of Service'] = df['Place of Service'].map(place_of_service_mapping)\n",
    "hcpcs_drug_indicator_mapping = {'Y': 'Drug Involved','N': 'No Drug'}\n",
    "df['HCPCS Drug Indicator'] = df['HCPCS Drug Indicator'].map(hcpcs_drug_indicator_mapping)\n",
    "\n",
    "\n",
    "binary_columns = ['Entity Type of the Provider','Place of Service','HCPCS Drug Indicator']\n",
    "for column in binary_columns:\n",
    "    fig = px.pie(df, names=column)\n",
    "    fig.update_layout(title=f'Distribution of {column}')\n",
    "    fig.update_traces(hoverinfo='label+percent', textinfo='value', textfont_size=12)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_mapping = {\n",
    "    'AL': 'Alabama', 'AK': 'Alaska', 'AZ': 'Arizona', 'AR': 'Arkansas', 'CA': 'California',\n",
    "    'CO': 'Colorado', 'CT': 'Connecticut', 'DE': 'Delaware', 'FL': 'Florida', 'GA': 'Georgia',\n",
    "    'HI': 'Hawaii', 'ID': 'Idaho', 'IL': 'Illinois', 'IN': 'Indiana', 'IA': 'Iowa', 'KS': 'Kansas',\n",
    "    'KY': 'Kentucky', 'LA': 'Louisiana', 'ME': 'Maine', 'MD': 'Maryland', 'MA': 'Massachusetts',\n",
    "    'MI': 'Michigan', 'MN': 'Minnesota', 'MS': 'Mississippi', 'MO': 'Missouri', 'MT': 'Montana',\n",
    "    'NE': 'Nebraska', 'NV': 'Nevada', 'NH': 'New Hampshire', 'NJ': 'New Jersey', 'NM': 'New Mexico',\n",
    "    'NY': 'New York', 'NC': 'North Carolina', 'ND': 'North Dakota', 'OH': 'Ohio', 'OK': 'Oklahoma',\n",
    "    'OR': 'Oregon', 'PA': 'Pennsylvania', 'RI': 'Rhode Island', 'SC': 'South Carolina', 'SD': 'South Dakota',\n",
    "    'TN': 'Tennessee', 'TX': 'Texas', 'UT': 'Utah', 'VT': 'Vermont', 'VA': 'Virginia', 'WA': 'Washington',\n",
    "    'WV': 'West Virginia', 'WI': 'Wisconsin', 'WY': 'Wyoming', 'DC': 'District of Columbia',\n",
    "    'AS': 'American Samoa', 'GU': 'Guam', 'MP': 'Northern Mariana Islands', 'PR': 'Puerto Rico',\n",
    "    'VI': 'Virgin Islands', 'UM': 'U.S. Minor Outlying Islands'\n",
    "}\n",
    "df['State Code of the Provider'] = df['State Code of the Provider'].map(state_mapping)\n",
    "multiple_columns = ['HCPCS Code','City of the Provider','State Code of the Provider','Provider Type']\n",
    "for column in multiple_columns:\n",
    "    top_ten = df.groupby(column)['Number of Services'].sum().nlargest(10).reset_index()\n",
    "    fig = px.bar(top_ten, x=column, y='Number of Services', color=column)\n",
    "    fig.update_layout(title=f'Top 10 {column} by Number of Services')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2- Numerical Features Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation matrix\n",
    "corr = df.corr()\n",
    "\n",
    "# Create the heatmap\n",
    "fig = px.imshow(\n",
    "    corr,\n",
    "    text_auto=True,\n",
    "    labels=dict(color=\"Correlation\"),\n",
    "    x=corr.columns.tolist(),\n",
    "    y=corr.index.tolist()\n",
    ")\n",
    "\n",
    "# Remove axis labels\n",
    "fig.update_xaxes(showticklabels=False)\n",
    "fig.update_yaxes(showticklabels=False)\n",
    "\n",
    "# Add hover text\n",
    "fig.update_traces(\n",
    "    hovertemplate=\"X: %{x}<br>Y: %{y}<br>Correlation: %{z:.2f}<extra></extra>\"\n",
    ")\n",
    "\n",
    "base_width = 800\n",
    "base_height = 600\n",
    "\n",
    "fig.update_layout(\n",
    "    width=base_width * 1.3,\n",
    "    height=base_height * 1.3,  # Added comma here\n",
    "    title={\n",
    "        'text': \"Correlation Heatmap\",\n",
    "        'y':0.95,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'\n",
    "    }\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#box plot in numerical columns to see Anomalies and outliers\n",
    "for column in columns_to_convert:\n",
    "    fig = px.box(df, y=column)\n",
    "    fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
